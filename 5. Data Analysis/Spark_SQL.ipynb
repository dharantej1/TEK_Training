{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97ae3e58",
   "metadata": {},
   "source": [
    "## Spark SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f59801c",
   "metadata": {},
   "source": [
    "### Block diagram - Double Click to expand\n",
    "<!--    \n",
    "+----------------------------------------------+\n",
    "|                  User Program                |\n",
    "+----------------------------------------------+\n",
    "                        |\n",
    "                        v\n",
    "+----------------+    +-----------------------+\n",
    "|    Data Source  |    |      SparkSession      |\n",
    "+----------------+    +-----------------------+\n",
    "                        |\n",
    "                        v\n",
    "+----------------+    +-----------------------+\n",
    "|  JDBC/ODBC API |    | Spark SQL Engine / API |\n",
    "+----------------+    +-----------------------+\n",
    "                        |\n",
    "                        v\n",
    "+----------------+    +-----------------------+\n",
    "|     Dataset    |    |    DataFrame / SQL     |\n",
    "+----------------+    +-----------------------+\n",
    "                        |\n",
    "                        v\n",
    "+----------------+    +-----------------------+\n",
    "|    Catalyst     |    |  Spark Core / Cluster  |\n",
    "|    Optimizer    |    +-----------------------+\n",
    "+----------------+               |\n",
    "                                 v\n",
    "+----------------------------------------------+\n",
    "|                    RDDs                      |\n",
    "+----------------------------------------------+\n",
    "\n",
    " -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45be860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: findspark in c:\\users\\pdharantej\\anaconda3\\lib\\site-packages (2.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install findspark\n",
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e22e0ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e874b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark=SparkSession.builder.appName('SparkSQL_UseCase').master('local[2]').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d91827d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HSC-PF1DSZBD.allegisgroup.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSQL_UseCase</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x280a1be1eb0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed392f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "rangeDF=spark.range(100).toDF('number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00b15523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[number: bigint]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rangeDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0a23694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     1|\n",
      "|     2|\n",
      "|     3|\n",
      "+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rangeDF.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9fa7a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rangeDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e653d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "evenDF=rangeDF.where('number%2==0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db7d68ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[number: bigint]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evenDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d8b7c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n",
      "|number|\n",
      "+------+\n",
      "|     0|\n",
      "|     2|\n",
      "|     4|\n",
      "|     6|\n",
      "|     8|\n",
      "+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evenDF.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5577f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.createDataFrame function\n",
    "\n",
    "nameDF=spark.createDataFrame([[1,'Alice',30,'Female'],\n",
    "                              [2,'Beneth',30,'Male'],\n",
    "                              [3,'Charlie',30,'Male'],\n",
    "                              [4,'Dharan',30,'Male']],['Id','Name','Age','Gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "597c2ae6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+------+\n",
      "| Id|   Name|Age|Gender|\n",
      "+---+-------+---+------+\n",
      "|  1|  Alice| 30|Female|\n",
      "|  2| Beneth| 30|  Male|\n",
      "|  3|Charlie| 30|  Male|\n",
      "+---+-------+---+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nameDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98fdb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing DataFrame from RDD\n",
    "\n",
    "sc=spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1afd9134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://HSC-PF1DSZBD.allegisgroup.com:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[2]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>SparkSQL_UseCase</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[2] appName=SparkSQL_UseCase>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ecd7e07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\pdharantej\\\\OneDrive - ALLEGIS GROUP\\\\Desktop\\\\TEK_Training\\\\5. Data Analysis'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# infer schema by using RDD\n",
    "\n",
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bab895df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempRDD=sc.textFile('./temp_data.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b942444",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13131"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06b5c211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tempRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a19fe4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1901\\t-78\\t1', '1901\\t-72\\t1', '1901\\t-94\\t1']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33992dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['1901', '-78', '1'], ['1901', '-72', '1'], ['1901', '-94', '1']]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitRDD=tempRDD.map(lambda record: record.split('\\t'))\n",
    "splitRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d42ccca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constructing the RDD using the Row object\n",
    "\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d9579b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "schemaRDD=splitRDD.map(lambda line: Row(year=line[0],temp=int(line[1]),status=int(line[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e6b1dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year='1901', temp=-78, status=1),\n",
       " Row(year='1901', temp=-72, status=1),\n",
       " Row(year='1901', temp=-94, status=1)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schemaRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "822ec85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----+------+\n",
      "|year|temp|status|\n",
      "+----+----+------+\n",
      "|1901| -78|     1|\n",
      "|1901| -72|     1|\n",
      "|1901| -94|     1|\n",
      "+----+----+------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF=spark.createDataFrame(schemaRDD)\n",
    "tempDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d43ef6d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(year='1901', temp=-78, status=1),\n",
       " Row(year='1901', temp=-72, status=1),\n",
       " Row(year='1901', temp=-94, status=1)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempDF.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cf27f5e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- year: string (nullable = true)\n",
      " |-- temp: long (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "57997742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233600"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reading a csv file as an RDD and then building the RDD as a dataframe\n",
    "\n",
    "# # read test.csv as RDD and convert it to dataframe\n",
    "testRDD=sc.textFile('./test.csv')\n",
    "testRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0ebcf5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['User_ID,Product_ID,Gender,Age,Occupation,City_Category,Stay_In_Current_City_Years,Marital_Status,Product_Category_1,Product_Category_2,Product_Category_3',\n",
       " '1000004,P00128942,M,46-50,7,B,2,1,1,11,',\n",
       " '1000009,P00113442,M,26-35,17,C,0,0,3,5,']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6cbc0210",
   "metadata": {},
   "outputs": [],
   "source": [
    "header=testRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "97bae5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "testRDD=testRDD.filter(lambda line: line!=header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9375ebdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After the header record is removed \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1000004,P00128942,M,46-50,7,B,2,1,1,11,'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('After the header record is removed ')\n",
    "testRDD.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd33277a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After splitting the records are : \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['1000004', 'P00128942', 'M', '46-50', '7', 'B', '2', '1', '1', '11', ''],\n",
       " ['1000009', 'P00113442', 'M', '26-35', '17', 'C', '0', '0', '3', '5', '']]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split data based on the separator\n",
    "splitRDD=testRDD.map(lambda line: line.split(','))\n",
    "print('After splitting the records are : \\n')\n",
    "splitRDD.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a416f18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "testRDDSchema=StructType([\n",
    "    StructField('User_Id', StringType(),True),\n",
    "    StructField('ProductId', StringType(),True),\n",
    "    StructField('Gender', StringType(),True),\n",
    "    StructField('Age', StringType(),True),\n",
    "    StructField('Occupation', StringType(),True),\n",
    "    StructField('City_Category', StringType(),True),\n",
    "    StructField('Stay_In_Current_City_Years', StringType(),True),\n",
    "    StructField('Marital_Status', StringType(),True),\n",
    "    StructField('Product_Category_1', StringType(),True),\n",
    "    StructField('Product_Category_2', StringType(),True),\n",
    "    StructField('Product_Category_3', StringType(),True),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "98a19143",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=spark.createDataFrame(data=splitRDD,schema=testRDDSchema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cb0fcf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+\n",
      "|User_Id|ProductId|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|\n",
      "+-------+---------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+\n",
      "|1000004|P00128942|     M|46-50|         7|            B|                         2|             1|                 1|                11|                  |\n",
      "|1000009|P00113442|     M|26-35|        17|            C|                         0|             0|                 3|                 5|                  |\n",
      "+-------+---------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "23dd5e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233599"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13dbda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "testSample=testDF.sample(False,0.1,98) # <without_duplication, sample_percentage, seed_value>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "815903e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23403"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testSample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ebdb31d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF=spark.read.format('csv').option('header','true').option('inferSchema','true').load('./train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e9388300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[User_ID: int, Product_ID: string, Gender: string, Age: string, Occupation: int, City_Category: string, Stay_In_Current_City_Years: string, Marital_Status: int, Product_Category_1: int, Product_Category_2: int, Product_Category_3: int, Purchase: int]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97c7f592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F| 0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "|1000001| P00087842|     F| 0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|\n",
      "|1000002| P00285442|     M|  55+|        16|            C|                        4+|             0|                 8|              null|              null|    7969|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|\n",
      "|1000004| P00346142|     M|46-50|         7|            B|                         2|             1|                 1|                15|              null|   15854|\n",
      "|1000004|  P0097242|     M|46-50|         7|            B|                         2|             1|                 1|                16|              null|   15686|\n",
      "|1000005| P00274942|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    7871|\n",
      "|1000005| P00251242|     M|26-35|        20|            A|                         1|             1|                 5|                11|              null|    5254|\n",
      "|1000005| P00014542|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    3957|\n",
      "|1000005| P00031342|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    6073|\n",
      "|1000005| P00145042|     M|26-35|        20|            A|                         1|             1|                 1|                 2|                 5|   15665|\n",
      "|1000006| P00231342|     F|51-55|         9|            A|                         1|             0|                 5|                 8|                14|    5378|\n",
      "|1000006| P00190242|     F|51-55|         9|            A|                         1|             0|                 4|                 5|              null|    2079|\n",
      "|1000006|  P0096642|     F|51-55|         9|            A|                         1|             0|                 2|                 3|                 4|   13055|\n",
      "|1000006| P00058442|     F|51-55|         9|            A|                         1|             0|                 5|                14|              null|    8851|\n",
      "|1000007| P00036842|     M|36-45|         1|            B|                         1|             1|                 1|                14|                16|   11788|\n",
      "|1000008| P00249542|     M|26-35|        12|            C|                        4+|             1|                 1|                 5|                15|   19614|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26a0f63a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54729"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSample=trainDF.sample(False, 0.1, 192)\n",
    "trainSample.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "77523569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "trainSamplePD=trainSample.toPandas()\n",
    "print(type(trainSample))\n",
    "print(type(trainSamplePD))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a8a1abbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainSamplePD = trainSamplePD.set_index('User_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "858df762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000005</td>\n",
       "      <td>P00031342</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>20</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000006</td>\n",
       "      <td>P00231342</td>\n",
       "      <td>F</td>\n",
       "      <td>51-55</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000006</td>\n",
       "      <td>P00190242</td>\n",
       "      <td>F</td>\n",
       "      <td>51-55</td>\n",
       "      <td>9</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000008</td>\n",
       "      <td>P00220442</td>\n",
       "      <td>M</td>\n",
       "      <td>26-35</td>\n",
       "      <td>12</td>\n",
       "      <td>C</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1000010</td>\n",
       "      <td>P00297942</td>\n",
       "      <td>F</td>\n",
       "      <td>36-45</td>\n",
       "      <td>1</td>\n",
       "      <td>B</td>\n",
       "      <td>4+</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID Product_ID Gender    Age  Occupation City_Category  \\\n",
       "0  1000005  P00031342      M  26-35          20             A   \n",
       "1  1000006  P00231342      F  51-55           9             A   \n",
       "2  1000006  P00190242      F  51-55           9             A   \n",
       "3  1000008  P00220442      M  26-35          12             C   \n",
       "4  1000010  P00297942      F  36-45           1             B   \n",
       "\n",
       "  Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                          1               1                   8   \n",
       "1                          1               0                   5   \n",
       "2                          1               0                   4   \n",
       "3                         4+               1                   5   \n",
       "4                         4+               1                   8   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0                 NaN                 NaN      6073  \n",
       "1                 8.0                14.0      5378  \n",
       "2                 5.0                 NaN      2079  \n",
       "3                14.0                 NaN      8584  \n",
       "4                 NaN                 NaN      5875  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSamplePD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7956d7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainSamplePD.to_csv('./2023_train_sample.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "01234b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: integer (nullable = true)\n",
      " |-- Product_Category_3: integer (nullable = true)\n",
      " |-- Purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c66bbae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(User_ID=1000001, Product_ID='P00069042', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=3, Product_Category_2=None, Product_Category_3=None, Purchase=8370),\n",
       " Row(User_ID=1000001, Product_ID='P00248942', Gender='F', Age='0-17', Occupation=10, City_Category='A', Stay_In_Current_City_Years='2', Marital_Status=0, Product_Category_1=1, Product_Category_2=6, Product_Category_3=14, Purchase=15200)]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "43b5fc44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0690f8bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in Training Dataset 550068\n",
      "Number of records in Testing Dataset 233599\n"
     ]
    }
   ],
   "source": [
    "print('Number of records in Training Dataset {}'.format(trainDF.count()))\n",
    "print('Number of records in Testing Dataset {}'.format(testDF.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e00f152f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "|summary|           User_ID|Product_ID|Gender|   Age|       Occupation|City_Category|Stay_In_Current_City_Years|     Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|         Purchase|\n",
      "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "|  count|            550068|    550068|550068|550068|           550068|       550068|                    550068|             550068|            550068|            376430|            166821|           550068|\n",
      "|   mean|1003028.8424013031|      null|  null|  null|8.076706879876669|         null|         1.468494139793958|0.40965298835780306| 5.404270017525106| 9.842329251122386|12.668243206790512|9263.968712959126|\n",
      "| stddev|1727.5915855313747|      null|  null|  null|6.522660487341741|         null|        0.9890866807573103| 0.4917701263173315| 3.936211369201365| 5.086589648693497| 4.125337631575274|5023.065393820575|\n",
      "|    min|           1000001| P00000142|     F|  0-17|                0|            A|                         0|                  0|                 1|                 2|                 3|               12|\n",
      "|    max|           1006040|  P0099942|     M|   55+|               20|            C|                        4+|                  1|                20|                18|                18|            23961|\n",
      "+-------+------------------+----------+------+------+-----------------+-------------+--------------------------+-------------------+------------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ede809fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+---------+------+------+-----------------+-------------+--------------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|           User_Id|ProductId|Gender|   Age|       Occupation|City_Category|Stay_In_Current_City_Years|    Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|\n",
      "+-------+------------------+---------+------+------+-----------------+-------------+--------------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|            233599|   233599|233599|233599|           233599|       233599|                    233599|            233599|            233599|            233599|            233599|\n",
      "|   mean|1003029.3568594044|     null|  null|  null|8.085407043694536|         null|        1.4682778997642345|0.4100702485883929| 5.276542279718663| 9.849586059346997|12.669453946534905|\n",
      "| stddev|  1726.50496799554|     null|  null|  null|6.521146481494506|         null|        0.9859464965736936|0.4918472073772924|  3.73638011226564| 5.094942849775061| 4.125944373515665|\n",
      "|    min|           1000001|P00000142|     F|  0-17|                0|            A|                         0|                 0|                 1|                  |                  |\n",
      "|    max|           1006040| P0099942|     M|   55+|                9|            C|                        4+|                 1|                 9|                 9|                 9|\n",
      "+-------+------------------+---------+------+------+-----------------+-------------+--------------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testDF.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4791d7b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|         Purchase|\n",
      "+-------+-----------------+\n",
      "|  count|           550068|\n",
      "|   mean|9263.968712959126|\n",
      "| stddev|5023.065393820575|\n",
      "|    min|               12|\n",
      "|    max|            23961|\n",
      "+-------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.describe('Purchase').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "62610de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF.createOrReplaceTempView('trainDFTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9baf63cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dff5ea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[User_ID: int, Product_ID: string, Gender: string, Age: string, Occupation: int, City_Category: string, Stay_In_Current_City_Years: string, Marital_Status: int, Product_Category_1: int, Product_Category_2: int, Product_Category_3: int, Purchase: int]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"select * from trainDFTable limit 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b9c74f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from trainDFTable limit 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e38b1d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Age: string, count: bigint]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFrameWay=trainDF.groupBy('Age').count()\n",
    "dataFrameWay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "435edcc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[Age#183], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(Age#183, 200), ENSURE_REQUIREMENTS, [plan_id=485]\n",
      "      +- HashAggregate(keys=[Age#183], functions=[partial_count(1)])\n",
      "         +- FileScan csv [Age#183] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/pdharantej/OneDrive - ALLEGIS GROUP/Desktop/TEK_Trainin..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Age:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataFrameWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e912715",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay=spark.sql('select Age, count(1) from trainDFTable group by Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5e8ed72c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[Age#183], functions=[count(1)])\n",
      "   +- Exchange hashpartitioning(Age#183, 200), ENSURE_REQUIREMENTS, [plan_id=498]\n",
      "      +- HashAggregate(keys=[Age#183], functions=[partial_count(1)])\n",
      "         +- FileScan csv [Age#183] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/C:/Users/pdharantej/OneDrive - ALLEGIS GROUP/Desktop/TEK_Trainin..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Age:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sqlWay.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c11c4126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above two statements give the same output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a450410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, col, column\n",
    "dfWay=trainDF.filter(col('Age')!='0-17').groupBy('Age').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "05fef3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age| count|\n",
      "+-----+------+\n",
      "|18-25| 99660|\n",
      "|26-35|219587|\n",
      "|46-50| 45701|\n",
      "|51-55| 38501|\n",
      "|36-45|110013|\n",
      "|  55+| 21504|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dfWay.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4f4e6c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlWay=spark.sql('select Age from trainDFTable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2b48c028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-------+\n",
      "| userID|User_ID|User_ID|\n",
      "+-------+-------+-------+\n",
      "|1000001|1000001|1000001|\n",
      "|1000001|1000001|1000001|\n",
      "|1000001|1000001|1000001|\n",
      "+-------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(expr('User_Id as userID'),col('User_ID'),'User_ID').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73065307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   user|\n",
      "+-------+\n",
      "|1000001|\n",
      "|1000001|\n",
      "+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(expr('User_ID as user')).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7a37f2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "| userID|\n",
      "+-------+\n",
      "|1000001|\n",
      "|1000001|\n",
      "+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select User_ID as userID from trainDFTable').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3b7961bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+\n",
      "| userId|productID|\n",
      "+-------+---------+\n",
      "|1000001|P00069042|\n",
      "|1000001|P00248942|\n",
      "+-------+---------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.selectExpr('User_ID as userId', 'product_ID as productID').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2ff24c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+-----+\n",
      "|User_ID|product_ID|  Age|\n",
      "+-------+----------+-----+\n",
      "|1000001| P00069042| 0-17|\n",
      "|1000001| P00248942| 0-17|\n",
      "|1000001| P00087842| 0-17|\n",
      "|1000001| P00085442| 0-17|\n",
      "|1000002| P00285442|  55+|\n",
      "|1000003| P00193542|26-35|\n",
      "|1000004| P00184942|46-50|\n",
      "|1000004| P00346142|46-50|\n",
      "|1000004|  P0097242|46-50|\n",
      "|1000005| P00274942|26-35|\n",
      "|1000005| P00251242|26-35|\n",
      "|1000005| P00014542|26-35|\n",
      "|1000005| P00031342|26-35|\n",
      "|1000005| P00145042|26-35|\n",
      "|1000006| P00231342|51-55|\n",
      "|1000006| P00190242|51-55|\n",
      "|1000006|  P0096642|51-55|\n",
      "|1000006| P00058442|51-55|\n",
      "|1000007| P00036842|36-45|\n",
      "|1000008| P00249542|26-35|\n",
      "+-------+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select('User_ID', 'product_ID', 'Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "cbf6e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|          1|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit\n",
    "trainDF.select('*', lit(1).alias('ConstantOne')).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1d35a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pyspark datastructures are immutable "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ce5228c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|          1|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select *, 1 as ConstantOne from trainDFTable limit 3').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5ca32ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDF=trainDF.withColumn('ConstantOne', lit(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0143d785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|          1|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9abe2795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+--------------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|OccuopationOne|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+--------------+\n",
      "|1000001| P00069042|     F| 0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|            11|\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|            11|\n",
      "|1000001| P00087842|     F| 0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|          1|            11|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|          1|            11|\n",
      "|1000002| P00285442|     M|  55+|        16|            C|                        4+|             0|                 8|              null|              null|    7969|          1|            17|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|          1|            16|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|          1|             8|\n",
      "|1000004| P00346142|     M|46-50|         7|            B|                         2|             1|                 1|                15|              null|   15854|          1|             8|\n",
      "|1000004|  P0097242|     M|46-50|         7|            B|                         2|             1|                 1|                16|              null|   15686|          1|             8|\n",
      "|1000005| P00274942|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    7871|          1|            21|\n",
      "|1000005| P00251242|     M|26-35|        20|            A|                         1|             1|                 5|                11|              null|    5254|          1|            21|\n",
      "|1000005| P00014542|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    3957|          1|            21|\n",
      "|1000005| P00031342|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    6073|          1|            21|\n",
      "|1000005| P00145042|     M|26-35|        20|            A|                         1|             1|                 1|                 2|                 5|   15665|          1|            21|\n",
      "|1000006| P00231342|     F|51-55|         9|            A|                         1|             0|                 5|                 8|                14|    5378|          1|            10|\n",
      "|1000006| P00190242|     F|51-55|         9|            A|                         1|             0|                 4|                 5|              null|    2079|          1|            10|\n",
      "|1000006|  P0096642|     F|51-55|         9|            A|                         1|             0|                 2|                 3|                 4|   13055|          1|            10|\n",
      "|1000006| P00058442|     F|51-55|         9|            A|                         1|             0|                 5|                14|              null|    8851|          1|            10|\n",
      "|1000007| P00036842|     M|36-45|         1|            B|                         1|             1|                 1|                14|                16|   11788|          1|             2|\n",
      "|1000008| P00249542|     M|26-35|        12|            C|                        4+|             1|                 1|                 5|                15|   19614|          1|            13|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.withColumn('OccuopationOne', trainDF.Occupation+1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fa03db6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+----------------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|SameCategoryCode|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+----------------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|            null|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|           false|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF=trainDF.withColumn('SameCategoryCode',\n",
    "                          trainDF['Product_Category_1']==trainDF['Product_Category_2'])\n",
    "tempDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f61eac45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+----------------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|SameCategoryCode|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+----------------+\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|           false|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|          1|           false|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|          1|           false|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+----------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.filter(col('SameCategoryCode')==False).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2fb8a2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+-------------------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|SimilarCategoryCode|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+-------------------+\n",
      "|1000001| P00069042|     F| 0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|               null|\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|              false|\n",
      "|1000001| P00087842|     F| 0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|          1|               null|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|          1|              false|\n",
      "|1000002| P00285442|     M|  55+|        16|            C|                        4+|             0|                 8|              null|              null|    7969|          1|               null|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|          1|              false|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|          1|              false|\n",
      "|1000004| P00346142|     M|46-50|         7|            B|                         2|             1|                 1|                15|              null|   15854|          1|              false|\n",
      "|1000004|  P0097242|     M|46-50|         7|            B|                         2|             1|                 1|                16|              null|   15686|          1|              false|\n",
      "|1000005| P00274942|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    7871|          1|               null|\n",
      "|1000005| P00251242|     M|26-35|        20|            A|                         1|             1|                 5|                11|              null|    5254|          1|              false|\n",
      "|1000005| P00014542|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    3957|          1|               null|\n",
      "|1000005| P00031342|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    6073|          1|               null|\n",
      "|1000005| P00145042|     M|26-35|        20|            A|                         1|             1|                 1|                 2|                 5|   15665|          1|              false|\n",
      "|1000006| P00231342|     F|51-55|         9|            A|                         1|             0|                 5|                 8|                14|    5378|          1|              false|\n",
      "|1000006| P00190242|     F|51-55|         9|            A|                         1|             0|                 4|                 5|              null|    2079|          1|              false|\n",
      "|1000006|  P0096642|     F|51-55|         9|            A|                         1|             0|                 2|                 3|                 4|   13055|          1|              false|\n",
      "|1000006| P00058442|     F|51-55|         9|            A|                         1|             0|                 5|                14|              null|    8851|          1|              false|\n",
      "|1000007| P00036842|     M|36-45|         1|            B|                         1|             1|                 1|                14|                16|   11788|          1|              false|\n",
      "|1000008| P00249542|     M|26-35|        12|            C|                        4+|             1|                 1|                 5|                15|   19614|          1|              false|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.withColumnRenamed('SameCategoryCode', 'SimilarCategoryCode').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "970d37f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F| 0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "|1000001| P00087842|     F| 0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|          1|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|          1|\n",
      "|1000002| P00285442|     M|  55+|        16|            C|                        4+|             0|                 8|              null|              null|    7969|          1|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|          1|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|          1|\n",
      "|1000004| P00346142|     M|46-50|         7|            B|                         2|             1|                 1|                15|              null|   15854|          1|\n",
      "|1000004|  P0097242|     M|46-50|         7|            B|                         2|             1|                 1|                16|              null|   15686|          1|\n",
      "|1000005| P00274942|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    7871|          1|\n",
      "|1000005| P00251242|     M|26-35|        20|            A|                         1|             1|                 5|                11|              null|    5254|          1|\n",
      "|1000005| P00014542|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    3957|          1|\n",
      "|1000005| P00031342|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    6073|          1|\n",
      "|1000005| P00145042|     M|26-35|        20|            A|                         1|             1|                 1|                 2|                 5|   15665|          1|\n",
      "|1000006| P00231342|     F|51-55|         9|            A|                         1|             0|                 5|                 8|                14|    5378|          1|\n",
      "|1000006| P00190242|     F|51-55|         9|            A|                         1|             0|                 4|                 5|              null|    2079|          1|\n",
      "|1000006|  P0096642|     F|51-55|         9|            A|                         1|             0|                 2|                 3|                 4|   13055|          1|\n",
      "|1000006| P00058442|     F|51-55|         9|            A|                         1|             0|                 5|                14|              null|    8851|          1|\n",
      "|1000007| P00036842|     M|36-45|         1|            B|                         1|             1|                 1|                14|                16|   11788|          1|\n",
      "|1000008| P00249542|     M|26-35|        12|            C|                        4+|             1|                 1|                 5|                15|   19614|          1|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.drop('SameCategoryCode').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "913387aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: integer (nullable = true)\n",
      " |-- Product_Category_3: integer (nullable = true)\n",
      " |-- Purchase: integer (nullable = true)\n",
      " |-- ConstantOne: integer (nullable = false)\n",
      " |-- SameCategoryCode: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c026d9f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: integer (nullable = true)\n",
      " |-- Product_Category_3: integer (nullable = true)\n",
      " |-- Purchase: string (nullable = true)\n",
      " |-- ConstantOne: integer (nullable = false)\n",
      " |-- SameCategoryCode: boolean (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tempDF.withColumn('Purchase', col('Purchase').cast('String')).printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6c511081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3631"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.select('Product_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c423ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "testDF=testDF.withColumn('Product_ID', col('ProductID'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "35baa347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3491"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testDF.select('Product_ID').distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8ca14616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_cat_in_test_train=testDF.select('Product_ID').subtract(trainDF.select('Product_ID'))\n",
    "diff_cat_in_test_train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "095397f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "186"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff_cat_in_train_test=trainDF.select('Product_ID').subtract(testDF.select('Product_ID'))\n",
    "diff_cat_in_train_test.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "30db13d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+------+\n",
      "|Age_Gender|    F|     M|\n",
      "+----------+-----+------+\n",
      "|      0-17| 5083| 10019|\n",
      "|     46-50|13199| 32502|\n",
      "|     18-25|24628| 75032|\n",
      "|     36-45|27170| 82843|\n",
      "|       55+| 5083| 16421|\n",
      "|     51-55| 9894| 28607|\n",
      "|     26-35|50752|168835|\n",
      "+----------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.crosstab('Age', 'Gender').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "171c686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+-----+------+-----+-----+-----+-----+\n",
      "|Gender_Age| 0-17|18-25| 26-35|36-45|46-50|51-55|  55+|\n",
      "+----------+-----+-----+------+-----+-----+-----+-----+\n",
      "|         F| 5083|24628| 50752|27170|13199| 9894| 5083|\n",
      "|         M|10019|75032|168835|82843|32502|28607|16421|\n",
      "+----------+-----+-----+------+-----+-----+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.crosstab('Gender', 'Age').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "e40e975a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|  Age|Gender| count|\n",
      "+-----+------+------+\n",
      "|51-55|     F|  9894|\n",
      "|18-25|     M| 75032|\n",
      "| 0-17|     F|  5083|\n",
      "|46-50|     M| 32502|\n",
      "|18-25|     F| 24628|\n",
      "|  55+|     M| 16421|\n",
      "|  55+|     F|  5083|\n",
      "|36-45|     M| 82843|\n",
      "|26-35|     F| 50752|\n",
      "| 0-17|     M| 10019|\n",
      "|36-45|     F| 27170|\n",
      "|51-55|     M| 28607|\n",
      "|26-35|     M|168835|\n",
      "|46-50|     F| 13199|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('Age', 'Gender').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7efffb38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+------+\n",
      "|Gender|  Age| count|\n",
      "+------+-----+------+\n",
      "|     F|46-50| 13199|\n",
      "|     M| 0-17| 10019|\n",
      "|     M|26-35|168835|\n",
      "|     M|51-55| 28607|\n",
      "|     M|18-25| 75032|\n",
      "|     M|  55+| 16421|\n",
      "|     F|51-55|  9894|\n",
      "|     F|36-45| 27170|\n",
      "|     F|18-25| 24628|\n",
      "|     F|  55+|  5083|\n",
      "|     M|36-45| 82843|\n",
      "|     F| 0-17|  5083|\n",
      "|     M|46-50| 32502|\n",
      "|     F|26-35| 50752|\n",
      "+------+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('Gender', 'Age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "ddc7d9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+------+\n",
      "|  age|Female|  Male|\n",
      "+-----+------+------+\n",
      "|18-25| 24628| 75032|\n",
      "|26-35| 50752|168835|\n",
      "| 0-17|  5083| 10019|\n",
      "|46-50| 13199| 32502|\n",
      "|51-55|  9894| 28607|\n",
      "|36-45| 27170| 82843|\n",
      "|  55+|  5083| 16421|\n",
      "+-----+------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select age, \n",
    "    sum(case when gender='F' then 1 else 0 end) as Female,\n",
    "    sum(case when gender='M' then 1 else 0 end) as Male\n",
    "    from trainDFTable\n",
    "    group by age\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "46de35eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age|Gender|\n",
      "+-----+------+\n",
      "|51-55|     F|\n",
      "|18-25|     M|\n",
      "| 0-17|     F|\n",
      "|46-50|     M|\n",
      "|18-25|     F|\n",
      "|  55+|     M|\n",
      "|  55+|     F|\n",
      "|36-45|     M|\n",
      "|26-35|     F|\n",
      "| 0-17|     M|\n",
      "|36-45|     F|\n",
      "|51-55|     M|\n",
      "|26-35|     M|\n",
      "|46-50|     F|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select('Age', 'Gender').dropDuplicates().show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ba36bf6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166821"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.dropna().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "23a8f2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166821"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.na.drop('any').count()\n",
    "# any column has the null values, the whole row gets to drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "b6b1f723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "166821"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.na.drop().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c1207ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F| 0-17|        10|            A|                         2|             0|                 3|                -1|                -1|    8370|          1|\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "|1000001| P00087842|     F| 0-17|        10|            A|                         2|             0|                12|                -1|                -1|    1422|          1|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|                -1|    1057|          1|\n",
      "|1000002| P00285442|     M|  55+|        16|            C|                        4+|             0|                 8|                -1|                -1|    7969|          1|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|                -1|   15227|          1|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|          1|\n",
      "|1000004| P00346142|     M|46-50|         7|            B|                         2|             1|                 1|                15|                -1|   15854|          1|\n",
      "|1000004|  P0097242|     M|46-50|         7|            B|                         2|             1|                 1|                16|                -1|   15686|          1|\n",
      "|1000005| P00274942|     M|26-35|        20|            A|                         1|             1|                 8|                -1|                -1|    7871|          1|\n",
      "|1000005| P00251242|     M|26-35|        20|            A|                         1|             1|                 5|                11|                -1|    5254|          1|\n",
      "|1000005| P00014542|     M|26-35|        20|            A|                         1|             1|                 8|                -1|                -1|    3957|          1|\n",
      "|1000005| P00031342|     M|26-35|        20|            A|                         1|             1|                 8|                -1|                -1|    6073|          1|\n",
      "|1000005| P00145042|     M|26-35|        20|            A|                         1|             1|                 1|                 2|                 5|   15665|          1|\n",
      "|1000006| P00231342|     F|51-55|         9|            A|                         1|             0|                 5|                 8|                14|    5378|          1|\n",
      "|1000006| P00190242|     F|51-55|         9|            A|                         1|             0|                 4|                 5|                -1|    2079|          1|\n",
      "|1000006|  P0096642|     F|51-55|         9|            A|                         1|             0|                 2|                 3|                 4|   13055|          1|\n",
      "|1000006| P00058442|     F|51-55|         9|            A|                         1|             0|                 5|                14|                -1|    8851|          1|\n",
      "|1000007| P00036842|     M|36-45|         1|            B|                         1|             1|                 1|                14|                16|   11788|          1|\n",
      "|1000008| P00249542|     M|26-35|        12|            C|                        4+|             1|                 1|                 5|                15|   19614|          1|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.fillna(-1).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "eeea5434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.fillna().show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "77a278cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|                -1|    8370|          1|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "|1000001| P00087842|     F|0-17|        10|            A|                         2|             0|                12|              null|                -1|    1422|          1|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fill_col_values={\n",
    "    \"Gender\": 'M',\n",
    "    'Purchase': 9999999,\n",
    "    'Product_Category_3': -1\n",
    "}\n",
    "trainDF.na.fill(fill_col_values).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "c3c8eb21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550068"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.na.replace([''], ['UNKNOWN'], ['Gender']).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "85f239c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purchase amount greater than 15000 {}\n"
     ]
    }
   ],
   "source": [
    "print('Purchase amount greater than 15000 {}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "a1df595c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.where('Purchase > 15000').where('Gender = \"F\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d47a3350",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.filter('Purchase > 15000').where('Gender = \"F\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d61bda7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.where((col('Purchase') > 15000) & (col('Gender')=='F')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "0c5eb12a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.filter((col('Purchase') > 15000) & (col('Gender')=='F')).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "40b6fb2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21429"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql('select * from trainDFTable where Purchase > 15000 and Gender = \"F\"').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8edccac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|DISTINCT_Age|\n",
      "+------------+\n",
      "|           7|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "trainDF.select(countDistinct('Age').alias('DISTINCT_Age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3ebbd624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|DISTINCT_Age|\n",
      "+------------+\n",
      "|           7|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.agg(countDistinct('Age').alias('DISTINCT_Age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "6c2b6e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "b71713d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender| Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1000001| P00069042|     F|0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|          1|\n",
      "|1000001| P00248942|     F|0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|          1|\n",
      "+-------+----------+------+----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f0d567e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------------+\n",
      "|min(Age)|    avg(Purchase)|\n",
      "+--------+-----------------+\n",
      "|    0-17|9263.968712959126|\n",
      "+--------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.agg(func.min('Age'), func.avg('Purchase')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d48cea46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|  Age| count|\n",
      "+-----+------+\n",
      "|18-25| 99660|\n",
      "|26-35|219587|\n",
      "| 0-17| 15102|\n",
      "|46-50| 45701|\n",
      "|51-55| 38501|\n",
      "|36-45|110013|\n",
      "|  55+| 21504|\n",
      "+-----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('Age').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "8aa0eabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "62fd0fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "?approx_count_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e3a8a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+\n",
      "|approx_count_distinct(Age)|\n",
      "+--------------------------+\n",
      "|                         7|\n",
      "+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(approx_count_distinct('Age',0.1)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "983c7d40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+\n",
      "|first(Product_ID)|last(Product_ID)|\n",
      "+-----------------+----------------+\n",
      "|        P00069042|       P00371644|\n",
      "+-----------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import first, last\n",
    "trainDF.select(first('Product_ID',True),last('Product_ID',True)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "903b8eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+\n",
      "|min(Purchase)|max(Purchase)|\n",
      "+-------------+-------------+\n",
      "|           12|        23961|\n",
      "+-------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import min, max\n",
    "trainDF.select(min('Purchase'),max('Purchase')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "201fd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, sum_distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "75174dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|sum(Purchase)|\n",
      "+-------------+\n",
      "|   5095812742|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(sum('Purchase')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "cb87e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|sum(DISTINCT Purchase)|\n",
      "+----------------------+\n",
      "|             208520914|\n",
      "+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.select(sum_distinct('Purchase')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "62b37c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-----------------+-----------------+\n",
      "|(total_purchases / total_transactions)|    avg_purchases|   mean_purchases|\n",
      "+--------------------------------------+-----------------+-----------------+\n",
      "|                     9263.968712959126|9263.968712959126|9263.968712959126|\n",
      "+--------------------------------------+-----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import sum, count, avg, expr\n",
    "trainDF.select(\n",
    "    count('Purchase').alias('total_transactions'),\n",
    "    sum('Purchase').alias('total_purchases'),\n",
    "    avg('Purchase').alias('avg_purchases'),\n",
    "    expr('mean(Purchase)').alias('mean_purchases')\n",
    ").selectExpr(\n",
    "    'total_purchases/total_transactions', 'avg_purchases', 'mean_purchases'\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "6bb96a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+--------------------+---------------------+\n",
      "|   var_pop(Purchase)| var_samp(Purchase)|stddev_pop(Purchase)|stddev_samp(Purchase)|\n",
      "+--------------------+-------------------+--------------------+---------------------+\n",
      "|2.5231140081385408E7|2.523118595059785E7|   5023.060827959921|    5023.065393820575|\n",
      "+--------------------+-------------------+--------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import var_pop, var_samp, stddev_pop, stddev_samp\n",
    "trainDF.select(var_pop('Purchase'), var_samp('Purchase'), stddev_pop('Purchase'), stddev_samp('Purchase')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "1cbff112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|    collect_set(Age)|   collect_list(Age)|\n",
      "+--------------------+--------------------+\n",
      "|[55+, 51-55, 0-17...|[0-17, 0-17, 0-17...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import collect_list, collect_set\n",
    "trainDF.agg(collect_set('Age'), collect_list('Age')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "8b5fa6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|    collect_set(Age)|   collect_list(Age)|\n",
      "+--------------------+--------------------+\n",
      "|[55+, 51-55, 0-17...|[0-17, 0-17, 0-17...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select collect_set(Age), collect_list(Age) from trainDFTable').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a917986b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+---------------+\n",
      "|  Age|  quan|count(Purchase)|\n",
      "+-----+------+---------------+\n",
      "|18-25| 99660|          99660|\n",
      "|26-35|219587|         219587|\n",
      "| 0-17| 15102|          15102|\n",
      "|46-50| 45701|          45701|\n",
      "|51-55| 38501|          38501|\n",
      "|36-45|110013|         110013|\n",
      "|  55+| 21504|          21504|\n",
      "+-----+------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('Age').agg(count('Purchase').alias('quan'),\n",
    "                          expr('count(Purchase)')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "a800b344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----------------+\n",
      "|  Age|    avg(Purchase)|\n",
      "+-----+-----------------+\n",
      "|18-25|9169.663606261289|\n",
      "|26-35|9252.690632869888|\n",
      "| 0-17|8933.464640444974|\n",
      "|46-50|9208.625697468327|\n",
      "|51-55|9534.808030960236|\n",
      "|36-45|9331.350694917874|\n",
      "|  55+|9336.280459449405|\n",
      "+-----+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('Age').agg({'Purchase':'mean'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "63c3394f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------------+\n",
      "|  Age|sum(Purchase)|\n",
      "+-----+-------------+\n",
      "|18-25|    913848675|\n",
      "|26-35|   2031770578|\n",
      "| 0-17|    134913183|\n",
      "|46-50|    420843403|\n",
      "|51-55|    367099644|\n",
      "|36-45|   1026569884|\n",
      "|  55+|    200767375|\n",
      "+-----+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.groupBy('Age').agg({'Purchase':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "e674695e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+-----------------------+-------------------+-------------+------------+---------------+-------------------------------+-----------------------+--------+----------------+-----------+-----------------------+---------------+\n",
      "|  Age|sum(City_Category)|sum(Product_Category_3)|sum(Marital_Status)|sum(Purchase)|sum(User_ID)|sum(Occupation)|sum(Stay_In_Current_City_Years)|sum(Product_Category_1)|sum(Age)|sum(ConstantOne)|sum(Gender)|sum(Product_Category_2)|sum(Product_ID)|\n",
      "+-----+------------------+-----------------------+-------------------+-------------+------------+---------------+-------------------------------+-----------------------+--------+----------------+-----------+-----------------------+---------------+\n",
      "|18-25|              null|                 388041|              21116|    913848675| 99939196632|         671348|                       116997.0|                 509371|    null|           99660|       null|                 654936|           null|\n",
      "|26-35|              null|                 846624|              86291|   2031770578|220270500414|        1734073|                       275611.0|                1166945|    null|          219587|       null|                1473278|           null|\n",
      "| 0-17|              null|                  57725|                  0|    134913183| 15143112813|         132309|                        20320.0|                  76775|    null|           15102|       null|                  96155|           null|\n",
      "|46-50|              null|                 173059|              33011|    420843403| 45846804203|         389239|                        51742.0|                 262424|    null|           45701|       null|                 315572|           null|\n",
      "|51-55|              null|                 146334|              27662|    367099644| 38615925320|         339198|                        44243.0|                 222313|    null|           38501|       null|                 267570|           null|\n",
      "|36-45|              null|                 424412|              43636|   1026569884|110350311441|         972225|                       148162.0|                 604438|    null|          110013|       null|                 750081|           null|\n",
      "|  55+|              null|                  77134|              13621|    200767375| 21568218459|         204346|                        26277.0|                 130450|    null|           21504|       null|                 147356|           null|\n",
      "+-----+------------------+-----------------------+-------------------+-------------+------------+---------------+-------------------------------+-----------------------+--------+----------------+-----------+-----------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exprs={x: 'sum' for x in trainDF.columns}\n",
    "trainDF.groupBy('Age').agg(exprs).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "3f66f14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Joins\n",
    "\n",
    "person=spark.createDataFrame(\n",
    "    [\n",
    "        (0,'Sundar Pichai',0,[250,100]),\n",
    "        (1,'Sergery',1,[500,250,100]),\n",
    "        (2,'William Oak',2,[100])\n",
    "    ]\n",
    ").toDF('id', 'name', 'graduate_program', 'role_status')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "4d6fc382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, name: string, graduate_program: bigint, role_status: array<bigint>]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "aea807f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+\n",
      "| id|         name|graduate_program|    role_status|\n",
      "+---+-------------+----------------+---------------+\n",
      "|  0|Sundar Pichai|               0|     [250, 100]|\n",
      "|  1|      Sergery|               1|[500, 250, 100]|\n",
      "|  2|  William Oak|               2|          [100]|\n",
      "+---+-------------+----------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "person.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d8b8f2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graduateProgram = spark.createDataFrame(\n",
    "    [\n",
    "        (0, 'MBA', 'School of MBA', 'Penn State University'),\n",
    "        (1, 'Ph.D', 'Computer Science', 'Stanford University'),\n",
    "        (2, 'Ph.D', 'School of Information', 'Oklhama University')\n",
    "    ]\n",
    ").toDF('id', 'degree', 'dept', 'school')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "61910a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, degree: string, dept: string, school: string]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graduateProgram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "4cd68f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+---------------------+---------------------+\n",
      "|id |degree|dept                 |school               |\n",
      "+---+------+---------------------+---------------------+\n",
      "|0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graduateProgram.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "aec25ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "roleStatus=spark.createDataFrame(\n",
    "    [\n",
    "        (500, 'President'),\n",
    "        (250, 'Founder'),\n",
    "        (100, 'Director')\n",
    "    ]\n",
    ").toDF('id', 'status')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "8e2c57cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint, status: string]"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roleStatus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "3a0e891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---------+\n",
      "|id |status   |\n",
      "+---+---------+\n",
      "|500|President|\n",
      "|250|Founder  |\n",
      "|100|Director |\n",
      "+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "roleStatus.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "3da92b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempView is for one spark session\n",
    "# globalView is when you have multiple spark sessions\n",
    "person.createOrReplaceTempView('personTbl')\n",
    "graduateProgram.createOrReplaceTempView('graduateProgramTbl')\n",
    "roleStatus.createOrReplaceTempView('roleStatusTbl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "987c7059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|id |name         |graduate_program|role_status    |id |degree|dept                 |school               |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|0  |Sundar Pichai|0               |[250, 100]     |0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Sergery      |1               |[500, 250, 100]|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |William Oak  |2               |[100]          |2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinExpression=person['graduate_program'] == graduateProgram['id']\n",
    "person.join(graduateProgram, joinExpression).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "3e82d3d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|id |name         |graduate_program|role_status    |id |degree|dept                 |school               |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|0  |Sundar Pichai|0               |[250, 100]     |0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Sergery      |1               |[500, 250, 100]|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |William Oak  |2               |[100]          |2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select * from personTbl join graduateProgramTbl\n",
    "    on personTbl.graduate_program=graduateProgramTbl.id\n",
    "''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2057ae0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|id |name         |graduate_program|role_status    |id |degree|dept                 |school               |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|0  |Sundar Pichai|0               |[250, 100]     |0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Sergery      |1               |[500, 250, 100]|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |William Oak  |2               |[100]          |2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType='inner'\n",
    "person.join(graduateProgram, joinExpression, joinType).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f19a916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|id |name         |graduate_program|role_status    |id |degree|dept                 |school               |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|0  |Sundar Pichai|0               |[250, 100]     |0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Sergery      |1               |[500, 250, 100]|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |William Oak  |2               |[100]          |2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType='outer'\n",
    "person.join(graduateProgram, joinExpression, joinType).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "db489fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|id |name         |graduate_program|role_status    |id |degree|dept                 |school               |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|0  |Sundar Pichai|0               |[250, 100]     |0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Sergery      |1               |[500, 250, 100]|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |William Oak  |2               |[100]          |2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType='left_outer'\n",
    "person.join(graduateProgram, joinExpression, joinType).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "917d37a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|id |name         |graduate_program|role_status    |id |degree|dept                 |school               |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "|0  |Sundar Pichai|0               |[250, 100]     |0  |MBA   |School of MBA        |Penn State University|\n",
      "|1  |Sergery      |1               |[500, 250, 100]|1  |Ph.D  |Computer Science     |Stanford University  |\n",
      "|2  |William Oak  |2               |[100]          |2  |Ph.D  |School of Information|Oklhama University   |\n",
      "+---+-------------+----------------+---------------+---+------+---------------------+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "joinType='right_outer'\n",
    "person.join(graduateProgram, joinExpression, joinType).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e78478ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------+---------------+---+---------+\n",
      "|personId|name         |graduate_program|role_status    |id |status   |\n",
      "+--------+-------------+----------------+---------------+---+---------+\n",
      "|0       |Sundar Pichai|0               |[250, 100]     |250|Founder  |\n",
      "|0       |Sundar Pichai|0               |[250, 100]     |100|Director |\n",
      "|1       |Sergery      |1               |[500, 250, 100]|500|President|\n",
      "|1       |Sergery      |1               |[500, 250, 100]|250|Founder  |\n",
      "|1       |Sergery      |1               |[500, 250, 100]|100|Director |\n",
      "|2       |William Oak  |2               |[100]          |100|Director |\n",
      "+--------+-------------+----------------+---------------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "person.withColumnRenamed('id', 'personId').join(roleStatus, expr('array_contains(role_status, id)')).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "ab37b1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+----------------+---------------+---+---------+\n",
      "|personId|name         |graduate_program|role_status    |id |status   |\n",
      "+--------+-------------+----------------+---------------+---+---------+\n",
      "|0       |Sundar Pichai|0               |[250, 100]     |250|Founder  |\n",
      "|0       |Sundar Pichai|0               |[250, 100]     |100|Director |\n",
      "|1       |Sergery      |1               |[500, 250, 100]|500|President|\n",
      "|1       |Sergery      |1               |[500, 250, 100]|250|Founder  |\n",
      "|1       |Sergery      |1               |[500, 250, 100]|100|Director |\n",
      "|2       |William Oak  |2               |[100]          |100|Director |\n",
      "+--------+-------------+----------------+---------------+---+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select * from \n",
    "    (select id as personId, name, graduate_program, role_status from personTbl)\n",
    "    inner join roleStatusTbl on array_contains(role_status, id)\n",
    "''').show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "d9226797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550068"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "1e34d47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample1=trainDF.sample(False, 0.1, 1234)\n",
    "sample2=trainDF.sample(False, 0.1, 2345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d1affe35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55488"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample1.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "c15f8f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54712"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "3afca87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitDF=trainDF.randomSplit([0.7, 0.3], seed=8787)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "120e15f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(splitDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "3ec0b6be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[User_ID: int, Product_ID: string, Gender: string, Age: string, Occupation: int, City_Category: string, Stay_In_Current_City_Years: string, Marital_Status: int, Product_Category_1: int, Product_Category_2: int, Product_Category_3: int, Purchase: int, ConstantOne: int],\n",
       " DataFrame[User_ID: int, Product_ID: string, Gender: string, Age: string, Occupation: int, City_Category: string, Stay_In_Current_City_Years: string, Marital_Status: int, Product_Category_1: int, Product_Category_2: int, Product_Category_3: int, Purchase: int, ConstantOne: int]]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "360bc95a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Row(User_ID=1000001), 1),\n",
       " (Row(User_ID=1000001), 1),\n",
       " (Row(User_ID=1000001), 1),\n",
       " (Row(User_ID=1000001), 1),\n",
       " (Row(User_ID=1000002), 1)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainDF.select('User_ID').rdd.map(lambda x: (x, 1)).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7b301d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|ConstantOne|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "|1002272| P00052842|     M|26-35|         0|            C|                         1|             0|                10|                15|              null|   23961|          1|\n",
      "|1003160| P00052842|     M|26-35|        17|            C|                         3|             0|                10|                15|              null|   23961|          1|\n",
      "|1001474| P00052842|     M|26-35|         4|            A|                         2|             1|                10|                15|              null|   23961|          1|\n",
      "|1003045| P00052842|     M|46-50|         1|            B|                         2|             1|                10|                15|              null|   23960|          1|\n",
      "|1005848| P00119342|     M|51-55|        20|            A|                         0|             1|                10|                13|              null|   23960|          1|\n",
      "|1001577| P00052842|     M|  55+|         0|            C|                         1|             1|                10|                15|              null|   23960|          1|\n",
      "|1005596| P00117642|     M|36-45|        12|            B|                         1|             0|                10|                16|              null|   23960|          1|\n",
      "|1003947| P00116142|     M|26-35|         0|            C|                         3|             0|                10|                13|                16|   23959|          1|\n",
      "|1001387| P00086242|     F|51-55|        13|            B|                         1|             1|                10|              null|              null|   23959|          1|\n",
      "|1001178| P00116142|     M|  55+|         0|            C|                         1|             1|                10|                13|                16|   23958|          1|\n",
      "|1005367| P00085342|     M|18-25|         4|            A|                         1|             0|                10|                13|              null|   23958|          1|\n",
      "|1003511| P00085342|     M|51-55|         0|            C|                         2|             1|                10|                13|              null|   23958|          1|\n",
      "|1004117| P00161842|     M|18-25|         4|            B|                        4+|             0|                10|                13|                16|   23958|          1|\n",
      "|1005102| P00052842|     M|26-35|        12|            C|                         2|             0|                10|                15|              null|   23956|          1|\n",
      "|1005716| P00052842|     M| 0-17|        10|            C|                        4+|             0|                10|                15|              null|   23955|          1|\n",
      "|1002359| P00085342|     M|  55+|        13|            C|                         1|             1|                10|                13|              null|   23955|          1|\n",
      "|1003301| P00086242|     F|26-35|         2|            B|                         3|             0|                10|              null|              null|   23955|          1|\n",
      "|1002788| P00085342|     M|  55+|         1|            B|                         0|             1|                10|                13|              null|   23954|          1|\n",
      "|1002274| P00052842|     M|18-25|         2|            B|                         3|             0|                10|                15|              null|   23954|          1|\n",
      "|1004520| P00116142|     M|26-35|         4|            C|                         1|             1|                10|                13|                16|   23953|          1|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainDF.orderBy(trainDF.Purchase.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c687c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_count_cat = diff_cat_in_test_train.rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "7092d112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P00300142',\n",
       " 'P00077642',\n",
       " 'P00092742',\n",
       " 'P00082142',\n",
       " 'P00062542',\n",
       " 'P00013042',\n",
       " 'P00279042',\n",
       " 'P00227242',\n",
       " 'P00359842',\n",
       " 'P00061642',\n",
       " 'P0099542',\n",
       " 'P00306842',\n",
       " 'P00140842',\n",
       " 'P00165542',\n",
       " 'P00268942',\n",
       " 'P00236842',\n",
       " 'P00172942',\n",
       " 'P00012642',\n",
       " 'P00336842',\n",
       " 'P00105742',\n",
       " 'P00309842',\n",
       " 'P00100242',\n",
       " 'P00315342',\n",
       " 'P00168242',\n",
       " 'P00156942',\n",
       " 'P00039042',\n",
       " 'P00056942',\n",
       " 'P00322642',\n",
       " 'P00249942',\n",
       " 'P00294942',\n",
       " 'P00106242',\n",
       " 'P00239542',\n",
       " 'P00074942',\n",
       " 'P00030342',\n",
       " 'P00063942',\n",
       " 'P00042642',\n",
       " 'P00322842',\n",
       " 'P00038942',\n",
       " 'P00270342',\n",
       " 'P00312642',\n",
       " 'P00166542',\n",
       " 'P00082642',\n",
       " 'P00253842',\n",
       " 'P00062242',\n",
       " 'P00058842',\n",
       " 'P00204642']"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_count_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "5fc0111a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "\n",
    "Function1=udf(lambda x: '-1' if x in not_count_cat else x, StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e6aeb9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=testDF.withColumn('NewProductId', Function1(testDF['ProductId'])).select('NewProductId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b5de0e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|NewProductId|\n",
      "+------------+\n",
      "|          -1|\n",
      "|          -1|\n",
      "|          -1|\n",
      "+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k.where(k['NewProductId']==-1).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "18e29bd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|          3.0|           2.0|\n",
      "|          3.0|           2.0|\n",
      "+-------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import lit, round, bround\n",
    "trainDF.select(round(lit('2.5')), bround(lit('2.5'))).show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "55248380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+--------------+--------------+\n",
      "|round(2.9, 0)|round(2.5, 0)|bround(2.4, 0)|bround(2.9, 0)|\n",
      "+-------------+-------------+--------------+--------------+\n",
      "|            3|            3|             2|             3|\n",
      "+-------------+-------------+--------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select round(2.9), round(2.5), bround(2.4), bround(2.9)').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ba147e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|round(2.5, 0)|bround(2.5, 0)|\n",
      "+-------------+--------------+\n",
      "|            3|             2|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('select round(2.5), bround(2.5)').show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a7bd4971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------+-----+-------+-------+\n",
      "| ltrim| rtrim| trim|   lpad|   rpad|\n",
      "+------+------+-----+-------+-------+\n",
      "|HELLO | HELLO|HELLO|  HELLO|HELLO  |\n",
      "|HELLO | HELLO|HELLO|  HELLO|HELLO  |\n",
      "+------+------+-----+-------+-------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# String Manipulations\n",
    "\n",
    "from pyspark.sql.functions import lit, ltrim, rtrim, lpad, rpad, trim\n",
    "trainDF.select(\n",
    "    ltrim(lit(\" HELLO \")).alias('ltrim'),\n",
    "    rtrim(lit(\" HELLO \")).alias('rtrim'),\n",
    "    trim(lit(\" HELLO \")).alias('trim'),\n",
    "    lpad(lit(\"HELLO\"),7,\" \").alias('lpad'),\n",
    "    rpad(lit(\"HELLO\"),7,\" \").alias('rpad')\n",
    ").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "6039ea6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------------+---------------+-----------------+------------------+\n",
      "|ltrim(  HELLO  )|rtrim(  HELLO  )|trim(  HELLO  )|lpad(HELLO, 3,  )|rpad(HELLO, 10,  )|\n",
      "+----------------+----------------+---------------+-----------------+------------------+\n",
      "|         HELLO  |           HELLO|          HELLO|              HEL|        HELLO     |\n",
      "|         HELLO  |           HELLO|          HELLO|              HEL|        HELLO     |\n",
      "|         HELLO  |           HELLO|          HELLO|              HEL|        HELLO     |\n",
      "+----------------+----------------+---------------+-----------------+------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select \n",
    "    ltrim('  HELLO  '),\n",
    "    rtrim('  HELLO  '),\n",
    "    trim('  HELLO  '),\n",
    "    lpad('HELLO',3,\" \"),\n",
    "    rpad('HELLO',10,\" \")\n",
    "    from trainDFTable\n",
    "''').show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "43fbe1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------+\n",
      "| GENDER_DECODE|GENDER|\n",
      "+--------------+------+\n",
      "|MALE_OR_FEMALE|     F|\n",
      "|MALE_OR_FEMALE|     F|\n",
      "|MALE_OR_FEMALE|     F|\n",
      "|MALE_OR_FEMALE|     F|\n",
      "|MALE_OR_FEMALE|     M|\n",
      "+--------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_replace\n",
    "regex_string='F|M'\n",
    "\n",
    "trainDF.select(\n",
    "    regexp_replace(col('Gender'), regex_string, 'MALE_OR_FEMALE').alias('GENDER_DECODE'), col('GENDER')\n",
    ").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "6b2b7b39",
   "metadata": {},
   "outputs": [
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o25.sql.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.liftedTree1$1(InMemoryCatalog.scala:123)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.createDatabase(InMemoryCatalog.scala:120)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:153)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$catalog$1(BaseSessionStateBuilder.scala:154)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:121)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:121)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:290)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isPersistentFunction(SessionCatalog.scala:1547)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.functionExists(V2SessionCatalog.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$23.applyOrElse(Analyzer.scala:2041)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$23.applyOrElse(Analyzer.scala:2032)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:589)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1228)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1227)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:498)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:589)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsDownWithPruning$1(QueryPlan.scala:159)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:200)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:200)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:211)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:216)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.immutable.List.map(List.scala:305)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:216)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:221)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:427)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:221)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDownWithPruning(QueryPlan.scala:159)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsWithPruning(QueryPlan.scala:130)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:245)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning$(AnalysisHelper.scala:242)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressionsWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2032)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2028)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:211)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)\r\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:208)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:200)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:200)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:231)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:227)\r\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:227)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:179)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:179)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:212)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:211)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:343)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:344)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:901)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 22 more\r\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_3044\\2814199669.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m spark.sql('''\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mselect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mregex_replace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mGender\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"F|M\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MALE_OR_FEMALE\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mDECODE_GENDER\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGENDER\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtrainDFTable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m ''').show(4)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\session.py\u001b[0m in \u001b[0;36msql\u001b[1;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[0;32m   1032\u001b[0m             \u001b[0msqlQuery\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1033\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1034\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1035\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1036\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1321\u001b[1;33m         return_value = get_return_value(\n\u001b[0m\u001b[0;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0;32m   1323\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyspark\\sql\\utils.py\u001b[0m in \u001b[0;36mdeco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 190\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    191\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\py4j\\protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[1;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[0;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m                 raise Py4JJavaError(\n\u001b[0m\u001b[0;32m    327\u001b[0m                     \u001b[1;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
      "\u001b[1;31mPy4JJavaError\u001b[0m: An error occurred while calling o25.sql.\n: java.lang.RuntimeException: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.getWinUtilsPath(Shell.java:735)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:270)\r\n\tat org.apache.hadoop.util.Shell.getSetPermissionCommand(Shell.java:286)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.setPermission(RawLocalFileSystem.java:978)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkOneDirWithMode(RawLocalFileSystem.java:660)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:700)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirsWithOptionalPermission(RawLocalFileSystem.java:699)\r\n\tat org.apache.hadoop.fs.RawLocalFileSystem.mkdirs(RawLocalFileSystem.java:672)\r\n\tat org.apache.hadoop.fs.ChecksumFileSystem.mkdirs(ChecksumFileSystem.java:788)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.liftedTree1$1(InMemoryCatalog.scala:123)\r\n\tat org.apache.spark.sql.catalyst.catalog.InMemoryCatalog.createDatabase(InMemoryCatalog.scala:120)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog$lzycompute(SharedState.scala:153)\r\n\tat org.apache.spark.sql.internal.SharedState.externalCatalog(SharedState.scala:140)\r\n\tat org.apache.spark.sql.internal.BaseSessionStateBuilder.$anonfun$catalog$1(BaseSessionStateBuilder.scala:154)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog$lzycompute(SessionCatalog.scala:121)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.externalCatalog(SessionCatalog.scala:121)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.databaseExists(SessionCatalog.scala:290)\r\n\tat org.apache.spark.sql.catalyst.catalog.SessionCatalog.isPersistentFunction(SessionCatalog.scala:1547)\r\n\tat org.apache.spark.sql.execution.datasources.v2.V2SessionCatalog.functionExists(V2SessionCatalog.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$23.applyOrElse(Analyzer.scala:2041)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$$anonfun$apply$23.applyOrElse(Analyzer.scala:2032)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$1(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:584)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.$anonfun$transformDownWithPruning$3(TreeNode.scala:589)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren(TreeNode.scala:1228)\r\n\tat org.apache.spark.sql.catalyst.trees.UnaryLike.mapChildren$(TreeNode.scala:1227)\r\n\tat org.apache.spark.sql.catalyst.expressions.UnaryExpression.mapChildren(Expression.scala:498)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformDownWithPruning(TreeNode.scala:589)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$transformExpressionsDownWithPruning$1(QueryPlan.scala:159)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$1(QueryPlan.scala:200)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:200)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:211)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$3(QueryPlan.scala:216)\r\n\tat scala.collection.TraversableLike.$anonfun$map$1(TraversableLike.scala:286)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat scala.collection.TraversableLike.map(TraversableLike.scala:286)\r\n\tat scala.collection.TraversableLike.map$(TraversableLike.scala:279)\r\n\tat scala.collection.immutable.List.map(List.scala:305)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.recursiveTransform$1(QueryPlan.scala:216)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.$anonfun$mapExpressions$4(QueryPlan.scala:221)\r\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:427)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:221)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsDownWithPruning(QueryPlan.scala:159)\r\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsWithPruning(QueryPlan.scala:130)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:245)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$$anonfun$resolveExpressionsWithPruning$1.applyOrElse(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$2(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:176)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.$anonfun$resolveOperatorsDownWithPruning$1(AnalysisHelper.scala:170)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.allowInvokingTransformsInAnalyzer(AnalysisHelper.scala:323)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning(AnalysisHelper.scala:168)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsDownWithPruning$(AnalysisHelper.scala:164)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsDownWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning(AnalysisHelper.scala:99)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveOperatorsWithPruning$(AnalysisHelper.scala:96)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveOperatorsWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning(AnalysisHelper.scala:244)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper.resolveExpressionsWithPruning$(AnalysisHelper.scala:242)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.LogicalPlan.resolveExpressionsWithPruning(LogicalPlan.scala:30)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2032)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer$LookupFunctions$.apply(Analyzer.scala:2028)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$2(RuleExecutor.scala:211)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft(IndexedSeqOptimized.scala:60)\r\n\tat scala.collection.IndexedSeqOptimized.foldLeft$(IndexedSeqOptimized.scala:68)\r\n\tat scala.collection.mutable.WrappedArray.foldLeft(WrappedArray.scala:38)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1(RuleExecutor.scala:208)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$execute$1$adapted(RuleExecutor.scala:200)\r\n\tat scala.collection.immutable.List.foreach(List.scala:431)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.execute(RuleExecutor.scala:200)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.org$apache$spark$sql$catalyst$analysis$Analyzer$$executeSameContext(Analyzer.scala:231)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$execute$1(Analyzer.scala:227)\r\n\tat org.apache.spark.sql.catalyst.analysis.AnalysisContext$.withNewAnalysisContext(Analyzer.scala:173)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:227)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.execute(Analyzer.scala:188)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.$anonfun$executeAndTrack$1(RuleExecutor.scala:179)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker$.withTracker(QueryPlanningTracker.scala:88)\r\n\tat org.apache.spark.sql.catalyst.rules.RuleExecutor.executeAndTrack(RuleExecutor.scala:179)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.$anonfun$executeAndCheck$1(Analyzer.scala:212)\r\n\tat org.apache.spark.sql.catalyst.plans.logical.AnalysisHelper$.markInAnalyzer(AnalysisHelper.scala:330)\r\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.executeAndCheck(Analyzer.scala:211)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$analyzed$1(QueryExecution.scala:76)\r\n\tat org.apache.spark.sql.catalyst.QueryPlanningTracker.measurePhase(QueryPlanningTracker.scala:111)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$2(QueryExecution.scala:185)\r\n\tat org.apache.spark.sql.execution.QueryExecution$.withInternalError(QueryExecution.scala:510)\r\n\tat org.apache.spark.sql.execution.QueryExecution.$anonfun$executePhase$1(QueryExecution.scala:185)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.execution.QueryExecution.executePhase(QueryExecution.scala:184)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed$lzycompute(QueryExecution.scala:76)\r\n\tat org.apache.spark.sql.execution.QueryExecution.analyzed(QueryExecution.scala:74)\r\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:66)\r\n\tat org.apache.spark.sql.Dataset$.$anonfun$ofRows$2(Dataset.scala:99)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:97)\r\n\tat org.apache.spark.sql.SparkSession.$anonfun$sql$1(SparkSession.scala:622)\r\n\tat org.apache.spark.sql.SparkSession.withActive(SparkSession.scala:779)\r\n\tat org.apache.spark.sql.SparkSession.sql(SparkSession.scala:617)\r\n\tat jdk.internal.reflect.GeneratedMethodAccessor97.invoke(Unknown Source)\r\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\r\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\r\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\r\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\r\n\tat py4j.Gateway.invoke(Gateway.java:282)\r\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\r\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\r\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\r\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\r\n\tat java.base/java.lang.Thread.run(Thread.java:834)\r\nCaused by: java.io.FileNotFoundException: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset. -see https://wiki.apache.org/hadoop/WindowsProblems\r\n\tat org.apache.hadoop.util.Shell.fileNotFoundException(Shell.java:547)\r\n\tat org.apache.hadoop.util.Shell.getHadoopHomeDir(Shell.java:568)\r\n\tat org.apache.hadoop.util.Shell.getQualifiedBin(Shell.java:591)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:688)\r\n\tat org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:79)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDurationHelper(Configuration.java:1907)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1867)\r\n\tat org.apache.hadoop.conf.Configuration.getTimeDuration(Configuration.java:1840)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.getShutdownTimeout(ShutdownHookManager.java:183)\r\n\tat org.apache.hadoop.util.ShutdownHookManager$HookEntry.<init>(ShutdownHookManager.java:207)\r\n\tat org.apache.hadoop.util.ShutdownHookManager.addShutdownHook(ShutdownHookManager.java:304)\r\n\tat org.apache.spark.util.SparkShutdownHookManager.install(ShutdownHookManager.scala:181)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks$lzycompute(ShutdownHookManager.scala:50)\r\n\tat org.apache.spark.util.ShutdownHookManager$.shutdownHooks(ShutdownHookManager.scala:48)\r\n\tat org.apache.spark.util.ShutdownHookManager$.addShutdownHook(ShutdownHookManager.scala:153)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<init>(ShutdownHookManager.scala:58)\r\n\tat org.apache.spark.util.ShutdownHookManager$.<clinit>(ShutdownHookManager.scala)\r\n\tat org.apache.spark.util.Utils$.createTempDir(Utils.scala:343)\r\n\tat org.apache.spark.deploy.SparkSubmit.prepareSubmitEnvironment(SparkSubmit.scala:344)\r\n\tat org.apache.spark.deploy.SparkSubmit.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:901)\r\n\tat org.apache.spark.deploy.SparkSubmit.doRunMain$1(SparkSubmit.scala:180)\r\n\tat org.apache.spark.deploy.SparkSubmit.submit(SparkSubmit.scala:203)\r\n\tat org.apache.spark.deploy.SparkSubmit.doSubmit(SparkSubmit.scala:90)\r\n\tat org.apache.spark.deploy.SparkSubmit$$anon$2.doSubmit(SparkSubmit.scala:1046)\r\n\tat org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:1055)\r\n\tat org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)\r\nCaused by: java.io.FileNotFoundException: HADOOP_HOME and hadoop.home.dir are unset.\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHomeInner(Shell.java:467)\r\n\tat org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:438)\r\n\tat org.apache.hadoop.util.Shell.<clinit>(Shell.java:515)\r\n\t... 22 more\r\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select \n",
    "    regex_replace(Gender, \"F|M\", \"MALE_OR_FEMALE\") as DECODE_GENDER, GENDER from trainDFTable\n",
    "''').show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "dcdc4930",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid non-printable character U+00A0 (2032349683.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\pdharantej\\AppData\\Local\\Temp\\ipykernel_3044\\2032349683.py\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    translate(col(\"Gender\"),\"FM\",\"01\"),\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid non-printable character U+00A0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import translate\n",
    "trainDF.select(\n",
    "    translate(col(\"Gender\"),\"FM\",\"01\"),\n",
    "    col(\"Gender\")\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2ed09ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+--------------------------+\n",
      "|id |today     |now                       |\n",
      "+---+----------+--------------------------+\n",
      "|0  |2023-04-13|2023-04-13 10:08:40.529102|\n",
      "|1  |2023-04-13|2023-04-13 10:08:40.529102|\n",
      "|2  |2023-04-13|2023-04-13 10:08:40.529102|\n",
      "+---+----------+--------------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import current_date,current_timestamp\n",
    "df_date =spark.range(10).withColumn(\"today\",current_date()).withColumn(\"now\",current_timestamp())\n",
    "df_date.show(3,truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "e1ffc026",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date.createOrReplaceTempView(\"dataDFTable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f035f1b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "+------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.functions import date_add,date_sub\n",
    "df_date.select(date_sub(col(\"today\"),5),date_add(col(\"today\"),5)).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "58924089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+\n",
      "|date_sub(today, 5)|date_add(today, 5)|\n",
      "+------------------+------------------+\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "|        2023-04-08|        2023-04-18|\n",
      "+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "    select \n",
    "    date_sub(today, 5),\n",
    "    date_add(today, 5)\n",
    "    from dataDFTable\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b8de694f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------+\n",
      "|datediff(week_ago, today)|\n",
      "+-------------------------+\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "|                       -7|\n",
      "+-------------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import datediff, months_between, to_date\n",
    "df_date.withColumn('week_ago', date_sub(col('today'),7)).select(datediff(col('week_ago'),col('today'))).show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce2496",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
